---
tags: [AI, 认知科学]
---

# 描述即污染

**提出者**：fangzhiyu
**日期**：2026年2月24日
**来源**：[[Claude Code认知架构：从skill系统看LLM的软控制]]

## 定义

当一段文本被放入LLM的上下文中用于"描述"某个功能或工具时，它不仅传递了信息，还改变了LLM对所有后续输出的概率分布。描述的存在本身就是一种干预，无论该功能是否被使用。

## 实证

1. `origin-regressor` skill的描述包含"第一性原理"、"审讯"等词 → AI在未调用该skill时使用了"宪法"一词
2. 对话历史中"侯世达"、"怪圈"高频出现 → AI把普通DOT流程图错误称为"怪圈图"
3. 所有skill的一行描述常驻上下文 → 即使从不调用，也在持续影响输出风格

## 机制

```
描述进入上下文
  → 进入注意力计算
    → 改变token概率分布
      → 输出中出现描述相关的词汇/概念
        → 用户无法区分这是"AI的判断"还是"被描述污染的结果"
```

## 推论

- 安装一个skill就是在改变AI的"性格"，即使从不调用
- 上下文中的任何文本都不是中性的，包括系统提示、工具描述、对话历史
- 这是 [[多层有损压缩]] 的又一个实例：描述是对功能的压缩，但压缩物本身产生了超出原意的影响

## 关联概念

- [[软触发]] — 描述污染是软触发机制的副作用
- [[多层有损压缩]] — 描述是压缩，压缩必然有损且有溢出
- [[超级个体公式]] — AI交互质量取决于你是否意识到这种污染的存在
