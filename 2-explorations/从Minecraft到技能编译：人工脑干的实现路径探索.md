---
tags: [AI, 认知科学, 工程]
---

# 从Minecraft到技能编译：人工脑干的实现路径探索

**讨论者**：fangzhiyu & Claude Opus 4.6
**日期**：2026年2月25日
**背景**：从人工脑干实验的环境选型出发，经由Minecraft agent生态调研、运动控制层级分析，发现了"技能编译"和"连续基质"两个关键问题

---

## 一、环境选型：为什么是Minecraft

原有实验设计（[[人工脑干：从目标真空到RL+LLM双系统架构]] 第四节）使用抽象的token预算环境。讨论中转向了游戏环境，最终选定Minecraft，因为它天然具备脑干实验需要的所有要素：

- 生存压力：血量、饥饿值、敌对生物
- 昼夜循环：夜晚威胁增加，需要节律性行为
- 资源管理：食物、工具、材料的获取和消耗
- 开放世界：没有固定目标，agent必须自己产生目标

## 二、Minecraft LLM Agent 生态

### Voyager（2023，NVIDIA）

第一个LLM驱动的Minecraft agent。6.7k stars，但代码更新不多，更像里程碑式研究项目。架构：LLM写JavaScript代码 → Mineflayer执行 → 技能库积累。纯"皮层"路线，没有生存压力概念。

### CraftJarvis 团队（最活跃）

围绕Minecraft agent建了完整生态，更新到2026年2月：

- **MineStudio**（344 stars）— Minecraft AI agent开发标准化工具包，支持在线RL训练
- **JARVIS-1**（388 stars）— 多模态版Voyager，能看屏幕不只靠文本
- **ROCKET-1** — 视觉-时序上下文提示，CVPR 2025。输入截图+交互类型，输出鼠标键盘动作
- **ROCKET-2** — ROCKET-1升级版，端到端打败末影龙，自发涌现搭桥行为，跨游戏零样本迁移
- **OpenHA** — 层级式agent架构，与我们的双层思路接近

### Cradle（2.5k stars，清华/BAAI）

通用计算机控制框架，截图+LLM推理+键鼠操作，不限于Minecraft。

### 关键观察

没有一个项目同时具备"快速反射"和"语言推理"。Voyager是纯皮层，ROCKET是纯小脑，没人做过真正的双系统。

## 三、运动控制的层级结构

讨论从一个问题开始：**人类控制身体时，内部的语言系统会说"我要控制手指按哪个键"吗？**

答案是不会。人类的运动控制是分层的：

| 层级 | 功能 | 速度 | 意识参与 |
|------|------|------|----------|
| 语言层（皮层） | "我要打这句话" | 慢 | 完全有意识 |
| 规划层（运动皮层） | 动作序列编排 | 中等 | 半意识 |
| 执行层（小脑/脊髓） | 具体肌肉收缩 | 快 | 无意识 |

语言只管最上层，越往下越"不可言说"。钢琴家无法用语言描述手指怎么弹快速跑动，但手知道。

### 映射到架构

LLM皮层不应该告诉ROCKET-2"鼠标向右移30像素"，应该只说"approach pig"。ROCKET-2的6种interaction type（hunt/mine/craft/approach/interact/switch）恰好是语义级别的命令粒度。

### 缺失的中间层

但如果LLM只发高层命令然后ROCKET-2黑箱执行，LLM在执行过程中是**失明**的。人类打字时虽然不用语言控制手指，但能感觉到手指在动、键盘的触感、打错了立刻察觉。

缺的不是精细控制命令，而是**执行过程中的感知反馈和中断机制** — 这恰好是脑干该干的事。

## 四、三层架构

从双系统扩展为三层：

| 层 | 人脑对应 | AI实现 | 训练方式 |
|---|---|---|---|
| 皮层 | 前额叶 | LLM | 预训练（已有） |
| 脑干 | 脑干+边缘系统 | RL策略网络 | 在线RL（生存奖励） |
| 小脑 | 小脑 | ROCKET-2 | 行为克隆（已有） |

脑干层是真正需要从零训练的部分。

## 五、LLM反向训练RL：康复训练类比

RL训练慢的根本原因：像婴儿一样从零摸索，99%的尝试是无意义的。

但康复训练的病人重新学走路比婴儿快得多 — 因为皮层还在，治疗师用语言指导："膝盖抬高一点""重心往左移"。

LLM可以反向加速RL训练：

| 康复训练 | AI对应 |
|---|---|
| 治疗师的语言指导 | LLM皮层 |
| 患者重新学走路 | RL脑干训练 |
| "膝盖抬高点" | LLM调整奖励函数（Eureka） |
| 治疗师扶着走 | LLM提供示范轨迹 |
| 安排训练计划 | LLM做课程设计 |

## 六、技能编译：从皮层到小脑的迁移

人类学打字的完整过程：

1. **认知阶段** — 用语言指导自己："F在这里，食指按这个……" 全靠皮层，很慢很累
2. **联结阶段** — 不用想每个键了，但还需要注意力。运动皮层和小脑开始接手
3. **自动化阶段** — 想到什么手指就打出来。皮层完全退出，小脑接管

神经层面：信号从"皮层→运动皮层→手指"的慢路径，通过反复练习被小脑"缓存"，转为"小脑→脊髓→手指"的快路径。

映射到实验路线图：
1. LLM皮层手动控制一切（认知阶段）
2. LLM的操作轨迹喂给RL训练（联结阶段）
3. RL策略学会了，LLM退出日常操控（自动化阶段）
4. LLM只在异常时介入（"踩空了"→皮层重新接管）

## 七、连续基质问题

**这是本次讨论的核心发现。**

在人脑里，"皮层把技能编译到小脑"不是两个独立系统在传文件。它们共享同一个神经基质 — 皮层和小脑之间有真实的神经纤维（皮质-桥脑-小脑通路），反复练习时信号在这条通路上流过无数次，突触强度逐渐改变，髓鞘逐渐加厚。"编译"是连续的、渐进的。

而LLM和RL是两个完全分离的程序，中间靠API调用传文本。没有共享的"神经通路"，没有渐进的信号重路由。要么LLM在控制，要么RL在控制，是硬切换。

**缺的不是通信协议，而是可以被"磨出来"的通路。**

### 可能的近似方案

- **蒸馏**（distillation）— LLM决策轨迹持续喂给RL，RL逐渐逼近LLM行为。边跑边学
- **软切换** — 不是二选一，而是0到1的混合权重。RL置信度低时偏向LLM，随训练推进滑向RL
- **共享表征空间** — LLM和RL不传文本传向量，在同一个嵌入空间交流

但这些都是近似。真正的神经可塑性 — 同一团神经元通过反复激活改变自身连接 — 在当前的分离架构里做不到。

---

*本次探索从Minecraft环境选型出发，经由运动控制层级分析和技能编译过程的追问，发现了一个根本性问题：当前AI的模块化架构缺少"连续基质"，无法实现人脑中从皮层到小脑的渐进式技能迁移。这可能是为什么没人真正实现过"技能编译"的深层原因。*
